% article document class appropriate for small (<100 pages) documents
\documentclass[draft, english, a4paper]{article}

% Packages provide additional functionality
%\usepackage{url}
\usepackage{fixme}
%\usepackage{lmodern}
\usepackage[final]{graphicx}%Force the graphics package to final, to force image inclusion
\graphicspath{{eps/}{images/}} %Set images/figures search path (relative to top latex file)
\usepackage[utf8]{inputenc}
\usepackage[left=3cm,top=4cm,right=3cm]{geometry}
\usepackage[final]{listings}
\usepackage[dvips,
            colorlinks=false,
            pdfduplex=DuplexFlipLongEdge,
            pdfborder={0 0 0},
            pdftitle={Playing with LEGO},
            pdfauthor={Mikael Moghadam, Kenni Peter Isaksen, Morten S. Laursen,
                Robot Technology,
                SDU,
                Odense,
                Danmark},
            pdfsubject={Introduction to Artificial Intelligence},
            pdfkeywords={LEGO, Sokoban, line follow},
            plainpages=false,
            final]{hyperref}

\title{Playing with LEGO}
\author{Mikael Moghadam, Kenni Peter Isaksen, Morten S. Laursen}

\begin{document}

\maketitle % reads info from \title and \author above


% where BibTeX should read the bibliography records from and what
% style of bibliography it should generate
%\bibliographystyle{plain}
%\bibliography{}
\section{Introduction}
\newpage
\tableofcontents
\newpage
\section{Architecture}
	\subsection{Division of responsibilities}
	\input{architecture.tex}
\section{Robot description}
        The purpose of this prototype is to perform the assignment as described by
        the planner. In order to accomplish this task a robot 
        has been created. The robot is created using the LEGO NXT platform. 
        \begin{figure}[htp]
            \centering
    	    \includegraphics[scale=0.3]{robot2}
	        \caption{Picture of the robot in it's current state}\label{fig:robotPic}
        \end{figure} 
	\subsection{Physical Construction} %Morten  
	    \label{robot:physicalContruction}
	    The robot is constructed using two motors which applies force to
	    each of their front wheels, this allows the robot to steer using skid steering.
	    In front of the wheels 2 light sensors is placed to detect the line, using
	    two sensors in place of just one sensor on top of the line allows for a wider
	    range of detection scenarios. One sensor would be forced to follow one
	    of the edges of the line, having two sensors allows for seeing the line
	    as in the middle (none of the sensors see's the line), slightly to the left (the left sensor see's the
	    line edge), far to the left (the left sensor see's the line), of cause the same
	    goes for the other direction. The way line edge and line can be seperated is
	    because the light sensors measure the amount of reflected light, when the area
	    scanned by the sensor is partially covered by line, the sensors values also only changes partially,
	    in other words the sensor measurements are far from binary. Having a higher detection resolution
	    allows for more fine grained controls, and because the sensors cover a larger area allows for more recovery
	    time without loosing sensor input.\\
	    In front of the two sensors another light sensor is placed on the right side of the vehicle,
	    this sensor is placed very far in front of the vehicle to detect crossing lines as early as possible, to allow
	    the vehicle to slow down as it cannot brake instantly. The placement of the three light
	    reflectance sensors is placed as illustrated in figure \ref{fig:lightSensorPlacement}
	    \begin{figure}[htp]
            \centering
    	    \includegraphics[scale=0.45]{lightSensorPlacement}
	        \caption{Illustration of light sensor placement, with the sensors mentioned S1-S3}\label{fig:lightSensorPlacement}
        \end{figure}	      
	\subsection{Robot architecture}
	    The software for the robot is implemented as a statemachine, which
	    interprets the commands given in the text file from the planner.
	    A statechart of the statemachine is shown in figure \ref{fig:RobotStateChart}
	    \begin{figure}[htp]
            \centering
    	    \includegraphics[scale=0.6]{TopLevelStateChart}
	        \caption{Statemachine of the Sokoban robot}\label{fig:RobotStateChart}
        \end{figure}
	    \subsubsection{Follow line}
	        The line following state has the responsibility of keeping the robot
		    constantly on the line using the sensors to allow for precise navigation.\\
		    \\
		    On figure \ref{fig:sensor_measurements} a plot of what the sensors
		    measures when driving on a line has been created. It is clear when
		    looking at the plot that the signal does not contain a lot of higher
		    frequency components and will therefore not achieve much from being filtered,
		    except less phasemargin because of the filterdelay. These data was measured
		    doing a evaluation of a proportional feedback control system.
		    \\
		    \begin{figure}[htp]
                \centering
    	        \includegraphics[scale=0.45]{sensor_measurements}
	            \caption{Raw samples of sensor measurements}\label{fig:sensor_measurements}
            \end{figure}
            \\
            \paragraph{Statemachine based}
            For making the control loop two different implementations has been
            tested, one using a simple state machine based solution, where the
            state machine tries to assess the position of the line as either 
            in the middle (none of the sensors see's the line), slightly to the left (the left sensor see's the
	         line edge), far to the left (the left sensor see's the line)
	        then from this approximation of the state of the relationship between
	        the line and the robot an action is performed by lowering the speed
	        on the wheel to close to the line according to the approximated state.\\
            \\
            \paragraph{PD-feedback based}
            Another option which has been tested is making a simple PD control loop
            using the light sensors, as the sensors are not entirely binary,
            but has a slight transition as more and more of the sensed area becomes
            line, it increases, a correction based on these small increases can 
            be seen as the oscillation between sample 100 - 200 on figure \ref{fig:sensor_measurements}
            Whereas the state machine based approach does not start correcting before reaching a threshold value.\\
            \\
            Having implemented both solutions on the vehicle the control loop based
            solution was chosen as it had clearly the best performance. This
            was proven by allowing both algorithms to follow a 2m stretch of
            straight line for 100 runs and comparing the amount of errors of both algorithms.
            \\
            In this test the statemachine based method failed in 13\% of the
            cases, where the PD regulator failed in only 2\% of the cases.
             
            
            %we need a statistical argument here...
            
		    %More detailed problem description with sensor position drawing
		    %measurement data examples.
		    %From there show proposed solutions
		    %Explain which one was chosen for which reasons, show flow diagrams
		    %of these two algorithms 
		    %Show incoming and output data from this block and the module test
%		    What is the responsibility of this block
%			Block interface
%			Block design / bird perspective flow chart 
%			Block test
	    \subsubsection{Turn left and turn right}
	        The turn states makes the robot turn around,
	        it does this by using the tachometer for feedback.
	        To achieve the correct turning radius a combination of turning one
	        wheel forward while the other is turned backwards is used. This
	        can be seen from the following pseudo code.
	        \begin{lstlisting}[language=Ruby, frame=single, basicstyle=\small, caption={TurnLeft Pseudo example}, label={code:turnleft}]
	        reset Tacho
	        until tachoCount > 1800 do:
	            TurnRightMotor Forward at 90% power
	            TurnLeftMotor Reverse at 30% power
	        return
	        \end{lstlisting}
	    \subsubsection{Turn around}
	        Turn around is more advanced than the simple turn left and right
	        states, this is because the requirements for a high precision turn is
	        higher, it therefore consists of a number of steps which it must pass
	        through.
	        \begin{enumerate}
	            \item Back off to avoid hitting the jewel when turning
	            \item Turn $160^o$ around based on the tachometer
	            \item Turn until the frontmost sensor see a line
	            \item Turn the last bit using the tacho
	        \end{enumerate}
	        As the starting inertia of the robot is relatively constant every time
	        and the remaining angular distance is also fairly constant, 
	        it works relatively accurately.
	        The algorithm was first realized in this way towards the end of the project
	        and therefore comprehensive testing on it's reliability was not performed.
	    \subsubsection{Read command}
	        This state reads the next character from the text file and 
	        transitions to the next state.
	    \subsubsection{Next command}
	        This state interprets the command read, it just directs the call
	        to the correct action state, left, right, turn around etc., based on 
	        an internal variable containing the vehicle's heading. 
%			What is the responsibility of this block
%			Block interface
%			Block design / bird perspective flow chart 
%			Block test
%			What is the responsibility of this block
%			Block interface
%			Block design / bird perspective flow chart 
%			Block test

	\subsection{Conclusion} %Morten
	   The completed vehicle was able to perform very well when going straight
	   and when performing turns in most cases, however turning right after a
	   180 degree turn proved to be very difficult for the vehicle, even though
	   the initial position after the 180 degree turn varied very little, the 
	   following turn proved difficult. If time had permitted it this could be 
	   improved a lot by relying more on the optical sensors doing the turn.
	   It is however noteworthy that the vehicle proved to be the fastest vehicle
	   at placing the first jewel in the competition, and during the competition for ten following trials
	   performed without error until the first turn following a 180 degree turn, where it failed consequently.
\section{Planner description}
    \input{sokoban_problem_discussion.tex}
	\subsection{Discussion of search algorithms} %Mikael
		\input{discussion_of_search_algorithms}
	\subsection{Implementation}
	\input{implementation_details.tex}
	\subsection{Performance evaluation}
	\input{performance_evaluation.tex}
\section{Conclusion}
\section{Discussion}
\bibliographystyle{plain}
\bibliography{bibtex_refs.bib}
\appendix
\end{document}

